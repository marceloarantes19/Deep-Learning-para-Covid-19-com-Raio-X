{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, Activation, MaxPooling2D, Flatten, Dense\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Marcelo\\AppData\\Local\\Temp\\ipykernel_10552\\3751071403.py:23: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df1.append(df2)\n"
     ]
    }
   ],
   "source": [
    "# Monta dataframe com nome dos arquivos\n",
    "fn1 = os.listdir(\"D:/DropB/Faculeste/TCC/Imagens/COVID-19_Radiography_Dataset/COVID/images\")\n",
    "fn2 = os.listdir(\"D:/DropB/Faculeste/TCC/Imagens/COVID-19_Radiography_Dataset/Normal/images\")\n",
    "\n",
    "ct1 = []\n",
    "for fn in fn1:\n",
    "  ct1.append([0])\n",
    "\n",
    "df1 = pd.DataFrame({\n",
    "  'arquivo': fn1,\n",
    "  'categoria': ct1\n",
    "})\n",
    "#df1\n",
    "\n",
    "ct2 = []\n",
    "for fn in fn2:\n",
    "  ct2.append([1])\n",
    "\n",
    "df2 = pd.DataFrame({\n",
    "  'arquivo': fn2,\n",
    "  'categoria': ct2\n",
    "})\n",
    "df = df1.append(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gerando dataframes de treinamento e de teste\n",
    "dfTreinamento = df.sample(frac=0.8, random_state=100)\n",
    "dfTeste = df[~df.index.isin(dfTreinamento.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 32\n",
    "height = 32\n",
    "depth = 3\n",
    "classes = 2\n",
    "inputShape = (height, width, depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11046 validated image filenames belonging to 2 classes.\n",
      "Found 1590 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "imgGen = ImageDataGenerator(rescale = 1./255, \n",
    "                            shear_range=0.25, \n",
    "                            zoom_range = 0.25, \n",
    "                            horizontal_flip = True)\n",
    "\n",
    "conjTreinamento = imgGen.flow_from_dataframe(dfTreinamento, \"D:/DropB/Faculeste/TCC/Imagens/dataFrame\", \n",
    "                                  x_col = 'arquivo',\n",
    "                                  y_col = 'categoria',\n",
    "                                  target_size=(width, height), \n",
    "                                  batch_size=32, \n",
    "                                  class_mode='categorical')\n",
    "\n",
    "conjTeste = imgGen.flow_from_dataframe(dfTeste, \"D:/DropB/Faculeste/TCC/Imagens/dataFrame\", \n",
    "                                  x_col = 'arquivo',\n",
    "                                  y_col = 'categoria',\n",
    "                                  target_size=(width, height), \n",
    "                                  batch_size=32, \n",
    "                                  class_mode='categorical')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 32, 32, 32)        896       \n",
      "                                                                 \n",
      " activation (Activation)     (None, 32, 32, 32)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 32768)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 65538     \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,434\n",
      "Trainable params: 66,434\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Marcelo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\gradient_descent.py:111: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# ShallowNet - Ajustar imagens para 32 x 32\n",
    "from shallowNet import ShallowNet\n",
    "shlwClf = ShallowNet()\n",
    "shlwClf = shlwClf.build(width=32, height=32, depth=3, classes=2)\n",
    "shlwClf.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1 (Conv2D)           (None, 28, 28, 6)         456       \n",
      "                                                                 \n",
      " average_pooling2d (AverageP  (None, 14, 14, 6)        0         \n",
      " ooling2D)                                                       \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 10, 10, 6)         906       \n",
      "                                                                 \n",
      " average_pooling2d_1 (Averag  (None, 5, 5, 6)          0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 5, 5, 120)         840       \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 3000)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 84)                252084    \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2)                 170       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 254,456\n",
      "Trainable params: 254,456\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Lenet5 - Ajustar imagens para 32 x 32\n",
    "from leNet5M import LeNet5M\n",
    "ln5Clf = LeNet5M()\n",
    "ln5clfM = ln5Clf.build(h=32, w=32, prof=3, cl=2)\n",
    "ln5clfM.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 8, 8, 96)          34944     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 4, 4, 96)         0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 4, 4, 256)         614656    \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 2, 2, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 2, 2, 384)         885120    \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 2, 2, 384)         1327488   \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 2, 2, 256)         884992    \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 1, 1, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 4096)              1052672   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 2)                 8194      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21,589,378\n",
      "Trainable params: 21,589,378\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# AlexNet - Ajustar imagens para 32 x 32\n",
    "from alexNet import AlexNet\n",
    "alxClf = AlexNet()\n",
    "alxClf = alxClf.build(width=32, height=32, depth=3, classes=2)\n",
    "alxClf.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_8 (Conv2D)           (None, 32, 32, 64)        1792      \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 32, 32, 64)        0         \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 32, 32, 64)       256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 32, 32, 64)        0         \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 32, 32, 64)        36928     \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 32, 32, 64)        0         \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 32, 32, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 16, 16, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 16, 16, 128)       73856     \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 16, 16, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 16, 16, 128)       147584    \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 16, 16, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 8, 8, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 8, 8, 256)         295168    \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 8, 8, 256)         0         \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 8, 8, 256)        1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 8, 8, 256)         0         \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 8, 8, 256)         0         \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 8, 8, 256)        1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 8, 8, 256)         0         \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " activation_8 (Activation)   (None, 8, 8, 256)         0         \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 8, 8, 256)        1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 4, 4, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 4, 4, 512)         1180160   \n",
      "                                                                 \n",
      " activation_9 (Activation)   (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 4, 4, 512)        2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      " conv2d_16 (Conv2D)          (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " activation_10 (Activation)  (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 4, 4, 512)        2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      " conv2d_17 (Conv2D)          (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " activation_11 (Activation)  (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 4, 4, 512)        2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 2, 2, 512)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_18 (Conv2D)          (None, 2, 2, 512)         2359808   \n",
      "                                                                 \n",
      " activation_12 (Activation)  (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " batch_normalization_10 (Bat  (None, 2, 2, 512)        2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " conv2d_19 (Conv2D)          (None, 2, 2, 512)         2359808   \n",
      "                                                                 \n",
      " activation_13 (Activation)  (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " batch_normalization_11 (Bat  (None, 2, 2, 512)        2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " conv2d_20 (Conv2D)          (None, 2, 2, 512)         2359808   \n",
      "                                                                 \n",
      " activation_14 (Activation)  (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " batch_normalization_12 (Bat  (None, 2, 2, 512)        2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 1, 1, 512)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 1, 1, 512)         0         \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 512)               262656    \n",
      "                                                                 \n",
      " activation_15 (Activation)  (None, 512)               0         \n",
      "                                                                 \n",
      " batch_normalization_13 (Bat  (None, 512)              2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 2)                 1026      \n",
      "                                                                 \n",
      " activation_16 (Activation)  (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,997,314\n",
      "Trainable params: 14,987,842\n",
      "Non-trainable params: 9,472\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# VGG16 - Ajustar imagens para 32 x 32\n",
    "from vgg16M import Vgg16M\n",
    "vggClf = Vgg16M()\n",
    "vggClf = vggClf.build(width=32, height=32, depth=3, classes=2)\n",
    "vggClf.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_4 (InputLayer)           [(None, 32, 32, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " zero_padding2d_6 (ZeroPadding2  (None, 38, 38, 3)   0           ['input_4[0][0]']                \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv1/conv (Conv2D)            (None, 16, 16, 64)   9408        ['zero_padding2d_6[0][0]']       \n",
      "                                                                                                  \n",
      " conv1/bn (BatchNormalization)  (None, 16, 16, 64)   256         ['conv1/conv[0][0]']             \n",
      "                                                                                                  \n",
      " conv1/relu (Activation)        (None, 16, 16, 64)   0           ['conv1/bn[0][0]']               \n",
      "                                                                                                  \n",
      " zero_padding2d_7 (ZeroPadding2  (None, 18, 18, 64)  0           ['conv1/relu[0][0]']             \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " pool1 (MaxPooling2D)           (None, 8, 8, 64)     0           ['zero_padding2d_7[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block1_0_bn (BatchNormal  (None, 8, 8, 64)    256         ['pool1[0][0]']                  \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_0_relu (Activatio  (None, 8, 8, 64)    0           ['conv2_block1_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_1_conv (Conv2D)   (None, 8, 8, 128)    8192        ['conv2_block1_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_1_bn (BatchNormal  (None, 8, 8, 128)   512         ['conv2_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_1_relu (Activatio  (None, 8, 8, 128)   0           ['conv2_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_2_conv (Conv2D)   (None, 8, 8, 32)     36864       ['conv2_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_concat (Concatena  (None, 8, 8, 96)    0           ['pool1[0][0]',                  \n",
      " te)                                                              'conv2_block1_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_0_bn (BatchNormal  (None, 8, 8, 96)    384         ['conv2_block1_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_0_relu (Activatio  (None, 8, 8, 96)    0           ['conv2_block2_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_1_conv (Conv2D)   (None, 8, 8, 128)    12288       ['conv2_block2_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_1_bn (BatchNormal  (None, 8, 8, 128)   512         ['conv2_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_1_relu (Activatio  (None, 8, 8, 128)   0           ['conv2_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_2_conv (Conv2D)   (None, 8, 8, 32)     36864       ['conv2_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_concat (Concatena  (None, 8, 8, 128)   0           ['conv2_block1_concat[0][0]',    \n",
      " te)                                                              'conv2_block2_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_0_bn (BatchNormal  (None, 8, 8, 128)   512         ['conv2_block2_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_0_relu (Activatio  (None, 8, 8, 128)   0           ['conv2_block3_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_1_conv (Conv2D)   (None, 8, 8, 128)    16384       ['conv2_block3_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_1_bn (BatchNormal  (None, 8, 8, 128)   512         ['conv2_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_1_relu (Activatio  (None, 8, 8, 128)   0           ['conv2_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_2_conv (Conv2D)   (None, 8, 8, 32)     36864       ['conv2_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_concat (Concatena  (None, 8, 8, 160)   0           ['conv2_block2_concat[0][0]',    \n",
      " te)                                                              'conv2_block3_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block4_0_bn (BatchNormal  (None, 8, 8, 160)   640         ['conv2_block3_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block4_0_relu (Activatio  (None, 8, 8, 160)   0           ['conv2_block4_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block4_1_conv (Conv2D)   (None, 8, 8, 128)    20480       ['conv2_block4_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block4_1_bn (BatchNormal  (None, 8, 8, 128)   512         ['conv2_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block4_1_relu (Activatio  (None, 8, 8, 128)   0           ['conv2_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block4_2_conv (Conv2D)   (None, 8, 8, 32)     36864       ['conv2_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block4_concat (Concatena  (None, 8, 8, 192)   0           ['conv2_block3_concat[0][0]',    \n",
      " te)                                                              'conv2_block4_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block5_0_bn (BatchNormal  (None, 8, 8, 192)   768         ['conv2_block4_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block5_0_relu (Activatio  (None, 8, 8, 192)   0           ['conv2_block5_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block5_1_conv (Conv2D)   (None, 8, 8, 128)    24576       ['conv2_block5_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block5_1_bn (BatchNormal  (None, 8, 8, 128)   512         ['conv2_block5_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block5_1_relu (Activatio  (None, 8, 8, 128)   0           ['conv2_block5_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block5_2_conv (Conv2D)   (None, 8, 8, 32)     36864       ['conv2_block5_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block5_concat (Concatena  (None, 8, 8, 224)   0           ['conv2_block4_concat[0][0]',    \n",
      " te)                                                              'conv2_block5_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block6_0_bn (BatchNormal  (None, 8, 8, 224)   896         ['conv2_block5_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block6_0_relu (Activatio  (None, 8, 8, 224)   0           ['conv2_block6_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block6_1_conv (Conv2D)   (None, 8, 8, 128)    28672       ['conv2_block6_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block6_1_bn (BatchNormal  (None, 8, 8, 128)   512         ['conv2_block6_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block6_1_relu (Activatio  (None, 8, 8, 128)   0           ['conv2_block6_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block6_2_conv (Conv2D)   (None, 8, 8, 32)     36864       ['conv2_block6_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block6_concat (Concatena  (None, 8, 8, 256)   0           ['conv2_block5_concat[0][0]',    \n",
      " te)                                                              'conv2_block6_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " pool2_bn (BatchNormalization)  (None, 8, 8, 256)    1024        ['conv2_block6_concat[0][0]']    \n",
      "                                                                                                  \n",
      " pool2_relu (Activation)        (None, 8, 8, 256)    0           ['pool2_bn[0][0]']               \n",
      "                                                                                                  \n",
      " pool2_conv (Conv2D)            (None, 8, 8, 128)    32768       ['pool2_relu[0][0]']             \n",
      "                                                                                                  \n",
      " pool2_pool (AveragePooling2D)  (None, 4, 4, 128)    0           ['pool2_conv[0][0]']             \n",
      "                                                                                                  \n",
      " conv3_block1_0_bn (BatchNormal  (None, 4, 4, 128)   512         ['pool2_pool[0][0]']             \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_0_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block1_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_1_conv (Conv2D)   (None, 4, 4, 128)    16384       ['conv3_block1_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_1_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_1_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_2_conv (Conv2D)   (None, 4, 4, 32)     36864       ['conv3_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_concat (Concatena  (None, 4, 4, 160)   0           ['pool2_pool[0][0]',             \n",
      " te)                                                              'conv3_block1_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_0_bn (BatchNormal  (None, 4, 4, 160)   640         ['conv3_block1_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_0_relu (Activatio  (None, 4, 4, 160)   0           ['conv3_block2_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_1_conv (Conv2D)   (None, 4, 4, 128)    20480       ['conv3_block2_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_1_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_1_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_2_conv (Conv2D)   (None, 4, 4, 32)     36864       ['conv3_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_concat (Concatena  (None, 4, 4, 192)   0           ['conv3_block1_concat[0][0]',    \n",
      " te)                                                              'conv3_block2_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_0_bn (BatchNormal  (None, 4, 4, 192)   768         ['conv3_block2_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_0_relu (Activatio  (None, 4, 4, 192)   0           ['conv3_block3_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_1_conv (Conv2D)   (None, 4, 4, 128)    24576       ['conv3_block3_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_1_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_1_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_2_conv (Conv2D)   (None, 4, 4, 32)     36864       ['conv3_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_concat (Concatena  (None, 4, 4, 224)   0           ['conv3_block2_concat[0][0]',    \n",
      " te)                                                              'conv3_block3_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_0_bn (BatchNormal  (None, 4, 4, 224)   896         ['conv3_block3_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_0_relu (Activatio  (None, 4, 4, 224)   0           ['conv3_block4_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_1_conv (Conv2D)   (None, 4, 4, 128)    28672       ['conv3_block4_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_1_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_1_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_2_conv (Conv2D)   (None, 4, 4, 32)     36864       ['conv3_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_concat (Concatena  (None, 4, 4, 256)   0           ['conv3_block3_concat[0][0]',    \n",
      " te)                                                              'conv3_block4_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block5_0_bn (BatchNormal  (None, 4, 4, 256)   1024        ['conv3_block4_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block5_0_relu (Activatio  (None, 4, 4, 256)   0           ['conv3_block5_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block5_1_conv (Conv2D)   (None, 4, 4, 128)    32768       ['conv3_block5_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block5_1_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block5_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block5_1_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block5_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block5_2_conv (Conv2D)   (None, 4, 4, 32)     36864       ['conv3_block5_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block5_concat (Concatena  (None, 4, 4, 288)   0           ['conv3_block4_concat[0][0]',    \n",
      " te)                                                              'conv3_block5_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block6_0_bn (BatchNormal  (None, 4, 4, 288)   1152        ['conv3_block5_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block6_0_relu (Activatio  (None, 4, 4, 288)   0           ['conv3_block6_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block6_1_conv (Conv2D)   (None, 4, 4, 128)    36864       ['conv3_block6_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block6_1_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block6_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block6_1_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block6_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block6_2_conv (Conv2D)   (None, 4, 4, 32)     36864       ['conv3_block6_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block6_concat (Concatena  (None, 4, 4, 320)   0           ['conv3_block5_concat[0][0]',    \n",
      " te)                                                              'conv3_block6_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block7_0_bn (BatchNormal  (None, 4, 4, 320)   1280        ['conv3_block6_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block7_0_relu (Activatio  (None, 4, 4, 320)   0           ['conv3_block7_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block7_1_conv (Conv2D)   (None, 4, 4, 128)    40960       ['conv3_block7_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block7_1_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block7_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block7_1_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block7_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block7_2_conv (Conv2D)   (None, 4, 4, 32)     36864       ['conv3_block7_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block7_concat (Concatena  (None, 4, 4, 352)   0           ['conv3_block6_concat[0][0]',    \n",
      " te)                                                              'conv3_block7_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block8_0_bn (BatchNormal  (None, 4, 4, 352)   1408        ['conv3_block7_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block8_0_relu (Activatio  (None, 4, 4, 352)   0           ['conv3_block8_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block8_1_conv (Conv2D)   (None, 4, 4, 128)    45056       ['conv3_block8_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block8_1_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block8_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block8_1_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block8_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block8_2_conv (Conv2D)   (None, 4, 4, 32)     36864       ['conv3_block8_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block8_concat (Concatena  (None, 4, 4, 384)   0           ['conv3_block7_concat[0][0]',    \n",
      " te)                                                              'conv3_block8_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block9_0_bn (BatchNormal  (None, 4, 4, 384)   1536        ['conv3_block8_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block9_0_relu (Activatio  (None, 4, 4, 384)   0           ['conv3_block9_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block9_1_conv (Conv2D)   (None, 4, 4, 128)    49152       ['conv3_block9_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block9_1_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block9_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block9_1_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block9_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block9_2_conv (Conv2D)   (None, 4, 4, 32)     36864       ['conv3_block9_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block9_concat (Concatena  (None, 4, 4, 416)   0           ['conv3_block8_concat[0][0]',    \n",
      " te)                                                              'conv3_block9_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block10_0_bn (BatchNorma  (None, 4, 4, 416)   1664        ['conv3_block9_concat[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv3_block10_0_relu (Activati  (None, 4, 4, 416)   0           ['conv3_block10_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv3_block10_1_conv (Conv2D)  (None, 4, 4, 128)    53248       ['conv3_block10_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv3_block10_1_bn (BatchNorma  (None, 4, 4, 128)   512         ['conv3_block10_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv3_block10_1_relu (Activati  (None, 4, 4, 128)   0           ['conv3_block10_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv3_block10_2_conv (Conv2D)  (None, 4, 4, 32)     36864       ['conv3_block10_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv3_block10_concat (Concaten  (None, 4, 4, 448)   0           ['conv3_block9_concat[0][0]',    \n",
      " ate)                                                             'conv3_block10_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv3_block11_0_bn (BatchNorma  (None, 4, 4, 448)   1792        ['conv3_block10_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv3_block11_0_relu (Activati  (None, 4, 4, 448)   0           ['conv3_block11_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv3_block11_1_conv (Conv2D)  (None, 4, 4, 128)    57344       ['conv3_block11_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv3_block11_1_bn (BatchNorma  (None, 4, 4, 128)   512         ['conv3_block11_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv3_block11_1_relu (Activati  (None, 4, 4, 128)   0           ['conv3_block11_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv3_block11_2_conv (Conv2D)  (None, 4, 4, 32)     36864       ['conv3_block11_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv3_block11_concat (Concaten  (None, 4, 4, 480)   0           ['conv3_block10_concat[0][0]',   \n",
      " ate)                                                             'conv3_block11_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv3_block12_0_bn (BatchNorma  (None, 4, 4, 480)   1920        ['conv3_block11_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv3_block12_0_relu (Activati  (None, 4, 4, 480)   0           ['conv3_block12_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv3_block12_1_conv (Conv2D)  (None, 4, 4, 128)    61440       ['conv3_block12_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv3_block12_1_bn (BatchNorma  (None, 4, 4, 128)   512         ['conv3_block12_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv3_block12_1_relu (Activati  (None, 4, 4, 128)   0           ['conv3_block12_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv3_block12_2_conv (Conv2D)  (None, 4, 4, 32)     36864       ['conv3_block12_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv3_block12_concat (Concaten  (None, 4, 4, 512)   0           ['conv3_block11_concat[0][0]',   \n",
      " ate)                                                             'conv3_block12_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " pool3_bn (BatchNormalization)  (None, 4, 4, 512)    2048        ['conv3_block12_concat[0][0]']   \n",
      "                                                                                                  \n",
      " pool3_relu (Activation)        (None, 4, 4, 512)    0           ['pool3_bn[0][0]']               \n",
      "                                                                                                  \n",
      " pool3_conv (Conv2D)            (None, 4, 4, 256)    131072      ['pool3_relu[0][0]']             \n",
      "                                                                                                  \n",
      " pool3_pool (AveragePooling2D)  (None, 2, 2, 256)    0           ['pool3_conv[0][0]']             \n",
      "                                                                                                  \n",
      " conv4_block1_0_bn (BatchNormal  (None, 2, 2, 256)   1024        ['pool3_pool[0][0]']             \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_0_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block1_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_1_conv (Conv2D)   (None, 2, 2, 128)    32768       ['conv4_block1_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block1_1_bn (BatchNormal  (None, 2, 2, 128)   512         ['conv4_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_1_relu (Activatio  (None, 2, 2, 128)   0           ['conv4_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_2_conv (Conv2D)   (None, 2, 2, 32)     36864       ['conv4_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block1_concat (Concatena  (None, 2, 2, 288)   0           ['pool3_pool[0][0]',             \n",
      " te)                                                              'conv4_block1_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_0_bn (BatchNormal  (None, 2, 2, 288)   1152        ['conv4_block1_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_0_relu (Activatio  (None, 2, 2, 288)   0           ['conv4_block2_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_1_conv (Conv2D)   (None, 2, 2, 128)    36864       ['conv4_block2_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_1_bn (BatchNormal  (None, 2, 2, 128)   512         ['conv4_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_1_relu (Activatio  (None, 2, 2, 128)   0           ['conv4_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_2_conv (Conv2D)   (None, 2, 2, 32)     36864       ['conv4_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_concat (Concatena  (None, 2, 2, 320)   0           ['conv4_block1_concat[0][0]',    \n",
      " te)                                                              'conv4_block2_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_0_bn (BatchNormal  (None, 2, 2, 320)   1280        ['conv4_block2_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_0_relu (Activatio  (None, 2, 2, 320)   0           ['conv4_block3_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_1_conv (Conv2D)   (None, 2, 2, 128)    40960       ['conv4_block3_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_1_bn (BatchNormal  (None, 2, 2, 128)   512         ['conv4_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_1_relu (Activatio  (None, 2, 2, 128)   0           ['conv4_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_2_conv (Conv2D)   (None, 2, 2, 32)     36864       ['conv4_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_concat (Concatena  (None, 2, 2, 352)   0           ['conv4_block2_concat[0][0]',    \n",
      " te)                                                              'conv4_block3_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_0_bn (BatchNormal  (None, 2, 2, 352)   1408        ['conv4_block3_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_0_relu (Activatio  (None, 2, 2, 352)   0           ['conv4_block4_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_1_conv (Conv2D)   (None, 2, 2, 128)    45056       ['conv4_block4_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_1_bn (BatchNormal  (None, 2, 2, 128)   512         ['conv4_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_1_relu (Activatio  (None, 2, 2, 128)   0           ['conv4_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_2_conv (Conv2D)   (None, 2, 2, 32)     36864       ['conv4_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_concat (Concatena  (None, 2, 2, 384)   0           ['conv4_block3_concat[0][0]',    \n",
      " te)                                                              'conv4_block4_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_0_bn (BatchNormal  (None, 2, 2, 384)   1536        ['conv4_block4_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_0_relu (Activatio  (None, 2, 2, 384)   0           ['conv4_block5_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_1_conv (Conv2D)   (None, 2, 2, 128)    49152       ['conv4_block5_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_1_bn (BatchNormal  (None, 2, 2, 128)   512         ['conv4_block5_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_1_relu (Activatio  (None, 2, 2, 128)   0           ['conv4_block5_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_2_conv (Conv2D)   (None, 2, 2, 32)     36864       ['conv4_block5_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_concat (Concatena  (None, 2, 2, 416)   0           ['conv4_block4_concat[0][0]',    \n",
      " te)                                                              'conv4_block5_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_0_bn (BatchNormal  (None, 2, 2, 416)   1664        ['conv4_block5_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_0_relu (Activatio  (None, 2, 2, 416)   0           ['conv4_block6_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_1_conv (Conv2D)   (None, 2, 2, 128)    53248       ['conv4_block6_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_1_bn (BatchNormal  (None, 2, 2, 128)   512         ['conv4_block6_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_1_relu (Activatio  (None, 2, 2, 128)   0           ['conv4_block6_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_2_conv (Conv2D)   (None, 2, 2, 32)     36864       ['conv4_block6_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_concat (Concatena  (None, 2, 2, 448)   0           ['conv4_block5_concat[0][0]',    \n",
      " te)                                                              'conv4_block6_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block7_0_bn (BatchNormal  (None, 2, 2, 448)   1792        ['conv4_block6_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block7_0_relu (Activatio  (None, 2, 2, 448)   0           ['conv4_block7_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block7_1_conv (Conv2D)   (None, 2, 2, 128)    57344       ['conv4_block7_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block7_1_bn (BatchNormal  (None, 2, 2, 128)   512         ['conv4_block7_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block7_1_relu (Activatio  (None, 2, 2, 128)   0           ['conv4_block7_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block7_2_conv (Conv2D)   (None, 2, 2, 32)     36864       ['conv4_block7_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block7_concat (Concatena  (None, 2, 2, 480)   0           ['conv4_block6_concat[0][0]',    \n",
      " te)                                                              'conv4_block7_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block8_0_bn (BatchNormal  (None, 2, 2, 480)   1920        ['conv4_block7_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block8_0_relu (Activatio  (None, 2, 2, 480)   0           ['conv4_block8_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block8_1_conv (Conv2D)   (None, 2, 2, 128)    61440       ['conv4_block8_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block8_1_bn (BatchNormal  (None, 2, 2, 128)   512         ['conv4_block8_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block8_1_relu (Activatio  (None, 2, 2, 128)   0           ['conv4_block8_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block8_2_conv (Conv2D)   (None, 2, 2, 32)     36864       ['conv4_block8_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block8_concat (Concatena  (None, 2, 2, 512)   0           ['conv4_block7_concat[0][0]',    \n",
      " te)                                                              'conv4_block8_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block9_0_bn (BatchNormal  (None, 2, 2, 512)   2048        ['conv4_block8_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block9_0_relu (Activatio  (None, 2, 2, 512)   0           ['conv4_block9_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block9_1_conv (Conv2D)   (None, 2, 2, 128)    65536       ['conv4_block9_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block9_1_bn (BatchNormal  (None, 2, 2, 128)   512         ['conv4_block9_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block9_1_relu (Activatio  (None, 2, 2, 128)   0           ['conv4_block9_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block9_2_conv (Conv2D)   (None, 2, 2, 32)     36864       ['conv4_block9_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block9_concat (Concatena  (None, 2, 2, 544)   0           ['conv4_block8_concat[0][0]',    \n",
      " te)                                                              'conv4_block9_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block10_0_bn (BatchNorma  (None, 2, 2, 544)   2176        ['conv4_block9_concat[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block10_0_relu (Activati  (None, 2, 2, 544)   0           ['conv4_block10_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block10_1_conv (Conv2D)  (None, 2, 2, 128)    69632       ['conv4_block10_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block10_1_bn (BatchNorma  (None, 2, 2, 128)   512         ['conv4_block10_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block10_1_relu (Activati  (None, 2, 2, 128)   0           ['conv4_block10_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block10_2_conv (Conv2D)  (None, 2, 2, 32)     36864       ['conv4_block10_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block10_concat (Concaten  (None, 2, 2, 576)   0           ['conv4_block9_concat[0][0]',    \n",
      " ate)                                                             'conv4_block10_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block11_0_bn (BatchNorma  (None, 2, 2, 576)   2304        ['conv4_block10_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block11_0_relu (Activati  (None, 2, 2, 576)   0           ['conv4_block11_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block11_1_conv (Conv2D)  (None, 2, 2, 128)    73728       ['conv4_block11_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block11_1_bn (BatchNorma  (None, 2, 2, 128)   512         ['conv4_block11_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block11_1_relu (Activati  (None, 2, 2, 128)   0           ['conv4_block11_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block11_2_conv (Conv2D)  (None, 2, 2, 32)     36864       ['conv4_block11_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block11_concat (Concaten  (None, 2, 2, 608)   0           ['conv4_block10_concat[0][0]',   \n",
      " ate)                                                             'conv4_block11_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block12_0_bn (BatchNorma  (None, 2, 2, 608)   2432        ['conv4_block11_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block12_0_relu (Activati  (None, 2, 2, 608)   0           ['conv4_block12_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block12_1_conv (Conv2D)  (None, 2, 2, 128)    77824       ['conv4_block12_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block12_1_bn (BatchNorma  (None, 2, 2, 128)   512         ['conv4_block12_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block12_1_relu (Activati  (None, 2, 2, 128)   0           ['conv4_block12_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block12_2_conv (Conv2D)  (None, 2, 2, 32)     36864       ['conv4_block12_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block12_concat (Concaten  (None, 2, 2, 640)   0           ['conv4_block11_concat[0][0]',   \n",
      " ate)                                                             'conv4_block12_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block13_0_bn (BatchNorma  (None, 2, 2, 640)   2560        ['conv4_block12_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block13_0_relu (Activati  (None, 2, 2, 640)   0           ['conv4_block13_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block13_1_conv (Conv2D)  (None, 2, 2, 128)    81920       ['conv4_block13_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block13_1_bn (BatchNorma  (None, 2, 2, 128)   512         ['conv4_block13_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block13_1_relu (Activati  (None, 2, 2, 128)   0           ['conv4_block13_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block13_2_conv (Conv2D)  (None, 2, 2, 32)     36864       ['conv4_block13_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block13_concat (Concaten  (None, 2, 2, 672)   0           ['conv4_block12_concat[0][0]',   \n",
      " ate)                                                             'conv4_block13_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block14_0_bn (BatchNorma  (None, 2, 2, 672)   2688        ['conv4_block13_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block14_0_relu (Activati  (None, 2, 2, 672)   0           ['conv4_block14_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block14_1_conv (Conv2D)  (None, 2, 2, 128)    86016       ['conv4_block14_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block14_1_bn (BatchNorma  (None, 2, 2, 128)   512         ['conv4_block14_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block14_1_relu (Activati  (None, 2, 2, 128)   0           ['conv4_block14_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block14_2_conv (Conv2D)  (None, 2, 2, 32)     36864       ['conv4_block14_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block14_concat (Concaten  (None, 2, 2, 704)   0           ['conv4_block13_concat[0][0]',   \n",
      " ate)                                                             'conv4_block14_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block15_0_bn (BatchNorma  (None, 2, 2, 704)   2816        ['conv4_block14_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block15_0_relu (Activati  (None, 2, 2, 704)   0           ['conv4_block15_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block15_1_conv (Conv2D)  (None, 2, 2, 128)    90112       ['conv4_block15_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block15_1_bn (BatchNorma  (None, 2, 2, 128)   512         ['conv4_block15_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block15_1_relu (Activati  (None, 2, 2, 128)   0           ['conv4_block15_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block15_2_conv (Conv2D)  (None, 2, 2, 32)     36864       ['conv4_block15_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block15_concat (Concaten  (None, 2, 2, 736)   0           ['conv4_block14_concat[0][0]',   \n",
      " ate)                                                             'conv4_block15_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block16_0_bn (BatchNorma  (None, 2, 2, 736)   2944        ['conv4_block15_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block16_0_relu (Activati  (None, 2, 2, 736)   0           ['conv4_block16_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block16_1_conv (Conv2D)  (None, 2, 2, 128)    94208       ['conv4_block16_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block16_1_bn (BatchNorma  (None, 2, 2, 128)   512         ['conv4_block16_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block16_1_relu (Activati  (None, 2, 2, 128)   0           ['conv4_block16_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block16_2_conv (Conv2D)  (None, 2, 2, 32)     36864       ['conv4_block16_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block16_concat (Concaten  (None, 2, 2, 768)   0           ['conv4_block15_concat[0][0]',   \n",
      " ate)                                                             'conv4_block16_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block17_0_bn (BatchNorma  (None, 2, 2, 768)   3072        ['conv4_block16_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block17_0_relu (Activati  (None, 2, 2, 768)   0           ['conv4_block17_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block17_1_conv (Conv2D)  (None, 2, 2, 128)    98304       ['conv4_block17_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block17_1_bn (BatchNorma  (None, 2, 2, 128)   512         ['conv4_block17_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block17_1_relu (Activati  (None, 2, 2, 128)   0           ['conv4_block17_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block17_2_conv (Conv2D)  (None, 2, 2, 32)     36864       ['conv4_block17_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block17_concat (Concaten  (None, 2, 2, 800)   0           ['conv4_block16_concat[0][0]',   \n",
      " ate)                                                             'conv4_block17_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block18_0_bn (BatchNorma  (None, 2, 2, 800)   3200        ['conv4_block17_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block18_0_relu (Activati  (None, 2, 2, 800)   0           ['conv4_block18_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block18_1_conv (Conv2D)  (None, 2, 2, 128)    102400      ['conv4_block18_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block18_1_bn (BatchNorma  (None, 2, 2, 128)   512         ['conv4_block18_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block18_1_relu (Activati  (None, 2, 2, 128)   0           ['conv4_block18_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block18_2_conv (Conv2D)  (None, 2, 2, 32)     36864       ['conv4_block18_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block18_concat (Concaten  (None, 2, 2, 832)   0           ['conv4_block17_concat[0][0]',   \n",
      " ate)                                                             'conv4_block18_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block19_0_bn (BatchNorma  (None, 2, 2, 832)   3328        ['conv4_block18_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block19_0_relu (Activati  (None, 2, 2, 832)   0           ['conv4_block19_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block19_1_conv (Conv2D)  (None, 2, 2, 128)    106496      ['conv4_block19_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block19_1_bn (BatchNorma  (None, 2, 2, 128)   512         ['conv4_block19_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block19_1_relu (Activati  (None, 2, 2, 128)   0           ['conv4_block19_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block19_2_conv (Conv2D)  (None, 2, 2, 32)     36864       ['conv4_block19_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block19_concat (Concaten  (None, 2, 2, 864)   0           ['conv4_block18_concat[0][0]',   \n",
      " ate)                                                             'conv4_block19_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block20_0_bn (BatchNorma  (None, 2, 2, 864)   3456        ['conv4_block19_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block20_0_relu (Activati  (None, 2, 2, 864)   0           ['conv4_block20_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block20_1_conv (Conv2D)  (None, 2, 2, 128)    110592      ['conv4_block20_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block20_1_bn (BatchNorma  (None, 2, 2, 128)   512         ['conv4_block20_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block20_1_relu (Activati  (None, 2, 2, 128)   0           ['conv4_block20_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block20_2_conv (Conv2D)  (None, 2, 2, 32)     36864       ['conv4_block20_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block20_concat (Concaten  (None, 2, 2, 896)   0           ['conv4_block19_concat[0][0]',   \n",
      " ate)                                                             'conv4_block20_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block21_0_bn (BatchNorma  (None, 2, 2, 896)   3584        ['conv4_block20_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block21_0_relu (Activati  (None, 2, 2, 896)   0           ['conv4_block21_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block21_1_conv (Conv2D)  (None, 2, 2, 128)    114688      ['conv4_block21_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block21_1_bn (BatchNorma  (None, 2, 2, 128)   512         ['conv4_block21_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block21_1_relu (Activati  (None, 2, 2, 128)   0           ['conv4_block21_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block21_2_conv (Conv2D)  (None, 2, 2, 32)     36864       ['conv4_block21_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block21_concat (Concaten  (None, 2, 2, 928)   0           ['conv4_block20_concat[0][0]',   \n",
      " ate)                                                             'conv4_block21_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block22_0_bn (BatchNorma  (None, 2, 2, 928)   3712        ['conv4_block21_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block22_0_relu (Activati  (None, 2, 2, 928)   0           ['conv4_block22_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block22_1_conv (Conv2D)  (None, 2, 2, 128)    118784      ['conv4_block22_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block22_1_bn (BatchNorma  (None, 2, 2, 128)   512         ['conv4_block22_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block22_1_relu (Activati  (None, 2, 2, 128)   0           ['conv4_block22_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block22_2_conv (Conv2D)  (None, 2, 2, 32)     36864       ['conv4_block22_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block22_concat (Concaten  (None, 2, 2, 960)   0           ['conv4_block21_concat[0][0]',   \n",
      " ate)                                                             'conv4_block22_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block23_0_bn (BatchNorma  (None, 2, 2, 960)   3840        ['conv4_block22_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block23_0_relu (Activati  (None, 2, 2, 960)   0           ['conv4_block23_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block23_1_conv (Conv2D)  (None, 2, 2, 128)    122880      ['conv4_block23_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block23_1_bn (BatchNorma  (None, 2, 2, 128)   512         ['conv4_block23_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block23_1_relu (Activati  (None, 2, 2, 128)   0           ['conv4_block23_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block23_2_conv (Conv2D)  (None, 2, 2, 32)     36864       ['conv4_block23_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block23_concat (Concaten  (None, 2, 2, 992)   0           ['conv4_block22_concat[0][0]',   \n",
      " ate)                                                             'conv4_block23_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block24_0_bn (BatchNorma  (None, 2, 2, 992)   3968        ['conv4_block23_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block24_0_relu (Activati  (None, 2, 2, 992)   0           ['conv4_block24_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block24_1_conv (Conv2D)  (None, 2, 2, 128)    126976      ['conv4_block24_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block24_1_bn (BatchNorma  (None, 2, 2, 128)   512         ['conv4_block24_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block24_1_relu (Activati  (None, 2, 2, 128)   0           ['conv4_block24_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block24_2_conv (Conv2D)  (None, 2, 2, 32)     36864       ['conv4_block24_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block24_concat (Concaten  (None, 2, 2, 1024)  0           ['conv4_block23_concat[0][0]',   \n",
      " ate)                                                             'conv4_block24_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " pool4_bn (BatchNormalization)  (None, 2, 2, 1024)   4096        ['conv4_block24_concat[0][0]']   \n",
      "                                                                                                  \n",
      " pool4_relu (Activation)        (None, 2, 2, 1024)   0           ['pool4_bn[0][0]']               \n",
      "                                                                                                  \n",
      " pool4_conv (Conv2D)            (None, 2, 2, 512)    524288      ['pool4_relu[0][0]']             \n",
      "                                                                                                  \n",
      " pool4_pool (AveragePooling2D)  (None, 1, 1, 512)    0           ['pool4_conv[0][0]']             \n",
      "                                                                                                  \n",
      " conv5_block1_0_bn (BatchNormal  (None, 1, 1, 512)   2048        ['pool4_pool[0][0]']             \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_0_relu (Activatio  (None, 1, 1, 512)   0           ['conv5_block1_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_1_conv (Conv2D)   (None, 1, 1, 128)    65536       ['conv5_block1_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_1_bn (BatchNormal  (None, 1, 1, 128)   512         ['conv5_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_1_relu (Activatio  (None, 1, 1, 128)   0           ['conv5_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_2_conv (Conv2D)   (None, 1, 1, 32)     36864       ['conv5_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_concat (Concatena  (None, 1, 1, 544)   0           ['pool4_pool[0][0]',             \n",
      " te)                                                              'conv5_block1_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_0_bn (BatchNormal  (None, 1, 1, 544)   2176        ['conv5_block1_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_0_relu (Activatio  (None, 1, 1, 544)   0           ['conv5_block2_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_1_conv (Conv2D)   (None, 1, 1, 128)    69632       ['conv5_block2_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_1_bn (BatchNormal  (None, 1, 1, 128)   512         ['conv5_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_1_relu (Activatio  (None, 1, 1, 128)   0           ['conv5_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_2_conv (Conv2D)   (None, 1, 1, 32)     36864       ['conv5_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_concat (Concatena  (None, 1, 1, 576)   0           ['conv5_block1_concat[0][0]',    \n",
      " te)                                                              'conv5_block2_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_0_bn (BatchNormal  (None, 1, 1, 576)   2304        ['conv5_block2_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_0_relu (Activatio  (None, 1, 1, 576)   0           ['conv5_block3_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_1_conv (Conv2D)   (None, 1, 1, 128)    73728       ['conv5_block3_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_1_bn (BatchNormal  (None, 1, 1, 128)   512         ['conv5_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_1_relu (Activatio  (None, 1, 1, 128)   0           ['conv5_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_2_conv (Conv2D)   (None, 1, 1, 32)     36864       ['conv5_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_concat (Concatena  (None, 1, 1, 608)   0           ['conv5_block2_concat[0][0]',    \n",
      " te)                                                              'conv5_block3_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block4_0_bn (BatchNormal  (None, 1, 1, 608)   2432        ['conv5_block3_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block4_0_relu (Activatio  (None, 1, 1, 608)   0           ['conv5_block4_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block4_1_conv (Conv2D)   (None, 1, 1, 128)    77824       ['conv5_block4_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block4_1_bn (BatchNormal  (None, 1, 1, 128)   512         ['conv5_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block4_1_relu (Activatio  (None, 1, 1, 128)   0           ['conv5_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block4_2_conv (Conv2D)   (None, 1, 1, 32)     36864       ['conv5_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block4_concat (Concatena  (None, 1, 1, 640)   0           ['conv5_block3_concat[0][0]',    \n",
      " te)                                                              'conv5_block4_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block5_0_bn (BatchNormal  (None, 1, 1, 640)   2560        ['conv5_block4_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block5_0_relu (Activatio  (None, 1, 1, 640)   0           ['conv5_block5_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block5_1_conv (Conv2D)   (None, 1, 1, 128)    81920       ['conv5_block5_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block5_1_bn (BatchNormal  (None, 1, 1, 128)   512         ['conv5_block5_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block5_1_relu (Activatio  (None, 1, 1, 128)   0           ['conv5_block5_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block5_2_conv (Conv2D)   (None, 1, 1, 32)     36864       ['conv5_block5_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block5_concat (Concatena  (None, 1, 1, 672)   0           ['conv5_block4_concat[0][0]',    \n",
      " te)                                                              'conv5_block5_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block6_0_bn (BatchNormal  (None, 1, 1, 672)   2688        ['conv5_block5_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block6_0_relu (Activatio  (None, 1, 1, 672)   0           ['conv5_block6_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block6_1_conv (Conv2D)   (None, 1, 1, 128)    86016       ['conv5_block6_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block6_1_bn (BatchNormal  (None, 1, 1, 128)   512         ['conv5_block6_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block6_1_relu (Activatio  (None, 1, 1, 128)   0           ['conv5_block6_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block6_2_conv (Conv2D)   (None, 1, 1, 32)     36864       ['conv5_block6_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block6_concat (Concatena  (None, 1, 1, 704)   0           ['conv5_block5_concat[0][0]',    \n",
      " te)                                                              'conv5_block6_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block7_0_bn (BatchNormal  (None, 1, 1, 704)   2816        ['conv5_block6_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block7_0_relu (Activatio  (None, 1, 1, 704)   0           ['conv5_block7_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block7_1_conv (Conv2D)   (None, 1, 1, 128)    90112       ['conv5_block7_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block7_1_bn (BatchNormal  (None, 1, 1, 128)   512         ['conv5_block7_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block7_1_relu (Activatio  (None, 1, 1, 128)   0           ['conv5_block7_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block7_2_conv (Conv2D)   (None, 1, 1, 32)     36864       ['conv5_block7_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block7_concat (Concatena  (None, 1, 1, 736)   0           ['conv5_block6_concat[0][0]',    \n",
      " te)                                                              'conv5_block7_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block8_0_bn (BatchNormal  (None, 1, 1, 736)   2944        ['conv5_block7_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block8_0_relu (Activatio  (None, 1, 1, 736)   0           ['conv5_block8_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block8_1_conv (Conv2D)   (None, 1, 1, 128)    94208       ['conv5_block8_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block8_1_bn (BatchNormal  (None, 1, 1, 128)   512         ['conv5_block8_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block8_1_relu (Activatio  (None, 1, 1, 128)   0           ['conv5_block8_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block8_2_conv (Conv2D)   (None, 1, 1, 32)     36864       ['conv5_block8_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block8_concat (Concatena  (None, 1, 1, 768)   0           ['conv5_block7_concat[0][0]',    \n",
      " te)                                                              'conv5_block8_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block9_0_bn (BatchNormal  (None, 1, 1, 768)   3072        ['conv5_block8_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block9_0_relu (Activatio  (None, 1, 1, 768)   0           ['conv5_block9_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block9_1_conv (Conv2D)   (None, 1, 1, 128)    98304       ['conv5_block9_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block9_1_bn (BatchNormal  (None, 1, 1, 128)   512         ['conv5_block9_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block9_1_relu (Activatio  (None, 1, 1, 128)   0           ['conv5_block9_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block9_2_conv (Conv2D)   (None, 1, 1, 32)     36864       ['conv5_block9_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block9_concat (Concatena  (None, 1, 1, 800)   0           ['conv5_block8_concat[0][0]',    \n",
      " te)                                                              'conv5_block9_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block10_0_bn (BatchNorma  (None, 1, 1, 800)   3200        ['conv5_block9_concat[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block10_0_relu (Activati  (None, 1, 1, 800)   0           ['conv5_block10_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block10_1_conv (Conv2D)  (None, 1, 1, 128)    102400      ['conv5_block10_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block10_1_bn (BatchNorma  (None, 1, 1, 128)   512         ['conv5_block10_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block10_1_relu (Activati  (None, 1, 1, 128)   0           ['conv5_block10_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block10_2_conv (Conv2D)  (None, 1, 1, 32)     36864       ['conv5_block10_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block10_concat (Concaten  (None, 1, 1, 832)   0           ['conv5_block9_concat[0][0]',    \n",
      " ate)                                                             'conv5_block10_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block11_0_bn (BatchNorma  (None, 1, 1, 832)   3328        ['conv5_block10_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block11_0_relu (Activati  (None, 1, 1, 832)   0           ['conv5_block11_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block11_1_conv (Conv2D)  (None, 1, 1, 128)    106496      ['conv5_block11_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block11_1_bn (BatchNorma  (None, 1, 1, 128)   512         ['conv5_block11_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block11_1_relu (Activati  (None, 1, 1, 128)   0           ['conv5_block11_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block11_2_conv (Conv2D)  (None, 1, 1, 32)     36864       ['conv5_block11_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block11_concat (Concaten  (None, 1, 1, 864)   0           ['conv5_block10_concat[0][0]',   \n",
      " ate)                                                             'conv5_block11_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block12_0_bn (BatchNorma  (None, 1, 1, 864)   3456        ['conv5_block11_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block12_0_relu (Activati  (None, 1, 1, 864)   0           ['conv5_block12_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block12_1_conv (Conv2D)  (None, 1, 1, 128)    110592      ['conv5_block12_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block12_1_bn (BatchNorma  (None, 1, 1, 128)   512         ['conv5_block12_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block12_1_relu (Activati  (None, 1, 1, 128)   0           ['conv5_block12_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block12_2_conv (Conv2D)  (None, 1, 1, 32)     36864       ['conv5_block12_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block12_concat (Concaten  (None, 1, 1, 896)   0           ['conv5_block11_concat[0][0]',   \n",
      " ate)                                                             'conv5_block12_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block13_0_bn (BatchNorma  (None, 1, 1, 896)   3584        ['conv5_block12_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block13_0_relu (Activati  (None, 1, 1, 896)   0           ['conv5_block13_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block13_1_conv (Conv2D)  (None, 1, 1, 128)    114688      ['conv5_block13_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block13_1_bn (BatchNorma  (None, 1, 1, 128)   512         ['conv5_block13_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block13_1_relu (Activati  (None, 1, 1, 128)   0           ['conv5_block13_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block13_2_conv (Conv2D)  (None, 1, 1, 32)     36864       ['conv5_block13_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block13_concat (Concaten  (None, 1, 1, 928)   0           ['conv5_block12_concat[0][0]',   \n",
      " ate)                                                             'conv5_block13_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block14_0_bn (BatchNorma  (None, 1, 1, 928)   3712        ['conv5_block13_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block14_0_relu (Activati  (None, 1, 1, 928)   0           ['conv5_block14_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block14_1_conv (Conv2D)  (None, 1, 1, 128)    118784      ['conv5_block14_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block14_1_bn (BatchNorma  (None, 1, 1, 128)   512         ['conv5_block14_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block14_1_relu (Activati  (None, 1, 1, 128)   0           ['conv5_block14_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block14_2_conv (Conv2D)  (None, 1, 1, 32)     36864       ['conv5_block14_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block14_concat (Concaten  (None, 1, 1, 960)   0           ['conv5_block13_concat[0][0]',   \n",
      " ate)                                                             'conv5_block14_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block15_0_bn (BatchNorma  (None, 1, 1, 960)   3840        ['conv5_block14_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block15_0_relu (Activati  (None, 1, 1, 960)   0           ['conv5_block15_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block15_1_conv (Conv2D)  (None, 1, 1, 128)    122880      ['conv5_block15_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block15_1_bn (BatchNorma  (None, 1, 1, 128)   512         ['conv5_block15_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block15_1_relu (Activati  (None, 1, 1, 128)   0           ['conv5_block15_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block15_2_conv (Conv2D)  (None, 1, 1, 32)     36864       ['conv5_block15_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block15_concat (Concaten  (None, 1, 1, 992)   0           ['conv5_block14_concat[0][0]',   \n",
      " ate)                                                             'conv5_block15_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block16_0_bn (BatchNorma  (None, 1, 1, 992)   3968        ['conv5_block15_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block16_0_relu (Activati  (None, 1, 1, 992)   0           ['conv5_block16_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block16_1_conv (Conv2D)  (None, 1, 1, 128)    126976      ['conv5_block16_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block16_1_bn (BatchNorma  (None, 1, 1, 128)   512         ['conv5_block16_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block16_1_relu (Activati  (None, 1, 1, 128)   0           ['conv5_block16_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block16_2_conv (Conv2D)  (None, 1, 1, 32)     36864       ['conv5_block16_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block16_concat (Concaten  (None, 1, 1, 1024)  0           ['conv5_block15_concat[0][0]',   \n",
      " ate)                                                             'conv5_block16_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " bn (BatchNormalization)        (None, 1, 1, 1024)   4096        ['conv5_block16_concat[0][0]']   \n",
      "                                                                                                  \n",
      " relu (Activation)              (None, 1, 1, 1024)   0           ['bn[0][0]']                     \n",
      "                                                                                                  \n",
      " pooling_layer (GlobalAveragePo  (None, 1024)        0           ['relu[0][0]']                   \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " output_layer (Dense)           (None, 2)            2050        ['pooling_layer[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 7,039,554\n",
      "Trainable params: 6,955,906\n",
      "Non-trainable params: 83,648\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# CheXNet - Ajustar imagens para 32 x 32\n",
    "from cxNet import CXNet\n",
    "cxClf = CXNet()\n",
    "cxClf = cxClf.build(width=32, height=32, depth=3, classes=2)\n",
    "cxClf.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shallow Net ***************************************************\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - ETA: 0s - loss: 1.4705 - accuracy: 0.6875WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 100 batches). You may need to use the repeat() function when building your dataset.\n",
      "5/5 [==============================] - 35s 9s/step - loss: 1.4705 - accuracy: 0.6875 - val_loss: 0.3118 - val_accuracy: 0.9113\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 5s 1s/step - loss: 0.5733 - accuracy: 0.8375\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 5s 930ms/step - loss: 0.6176 - accuracy: 0.7375\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 5s 1s/step - loss: 0.5951 - accuracy: 0.7250\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 5s 1s/step - loss: 0.5528 - accuracy: 0.7500\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 5s 967ms/step - loss: 0.7015 - accuracy: 0.6750\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 5s 922ms/step - loss: 0.5870 - accuracy: 0.7125\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 4s 733ms/step - loss: 0.6161 - accuracy: 0.6716\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 5s 940ms/step - loss: 0.6020 - accuracy: 0.7063\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 5s 873ms/step - loss: 0.5946 - accuracy: 0.6875\n",
      "LeNet 5 *******************************************************\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.6096 - accuracy: 0.7375WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 100 batches). You may need to use the repeat() function when building your dataset.\n",
      "5/5 [==============================] - 9s 2s/step - loss: 0.6096 - accuracy: 0.7375 - val_loss: 0.4697 - val_accuracy: 0.9113\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 5s 931ms/step - loss: 1.6816 - accuracy: 0.4375\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 4s 776ms/step - loss: 0.8862 - accuracy: 0.6562\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 4s 886ms/step - loss: 0.6991 - accuracy: 0.6187\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 4s 734ms/step - loss: 0.6355 - accuracy: 0.6812\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 3s 691ms/step - loss: 0.5940 - accuracy: 0.7250\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 4s 772ms/step - loss: 0.5450 - accuracy: 0.7750\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 4s 699ms/step - loss: 0.6057 - accuracy: 0.7063\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 4s 841ms/step - loss: 0.6314 - accuracy: 0.7250\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 5s 764ms/step - loss: 0.5606 - accuracy: 0.7688\n",
      "AlexNet *******************************************************\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.6237 - accuracy: 0.6313WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 100 batches). You may need to use the repeat() function when building your dataset.\n",
      "5/5 [==============================] - 9s 2s/step - loss: 0.6237 - accuracy: 0.6313 - val_loss: 0.3882 - val_accuracy: 0.9113\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 4s 731ms/step - loss: 0.5483 - accuracy: 0.7688\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 4s 693ms/step - loss: 0.5421 - accuracy: 0.7750\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 4s 735ms/step - loss: 0.5635 - accuracy: 0.7437\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 4s 725ms/step - loss: 0.5951 - accuracy: 0.7000\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 4s 668ms/step - loss: 0.5407 - accuracy: 0.7750\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 4s 728ms/step - loss: 0.5133 - accuracy: 0.7750\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 4s 683ms/step - loss: 0.5860 - accuracy: 0.7312\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 4s 679ms/step - loss: 0.6072 - accuracy: 0.7375\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 3s 609ms/step - loss: 0.5468 - accuracy: 0.7563\n",
      "Vgg16 *********************************************************\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - ETA: 0s - loss: 2.0361 - accuracy: 0.5437WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 100 batches). You may need to use the repeat() function when building your dataset.\n",
      "5/5 [==============================] - 21s 5s/step - loss: 2.0361 - accuracy: 0.5437 - val_loss: 21272.4102 - val_accuracy: 0.9113\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 8s 1s/step - loss: 2.3168 - accuracy: 0.5437\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 8s 1s/step - loss: 2.1384 - accuracy: 0.6000\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 8s 1s/step - loss: 1.8537 - accuracy: 0.6375\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 8s 1s/step - loss: 1.2605 - accuracy: 0.6625\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 8s 2s/step - loss: 1.6843 - accuracy: 0.6500\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 8s 1s/step - loss: 1.8694 - accuracy: 0.6250\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 8s 1s/step - loss: 1.0180 - accuracy: 0.7875\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 8s 1s/step - loss: 1.4595 - accuracy: 0.6687\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 8s 1s/step - loss: 1.2525 - accuracy: 0.6375\n",
      "cxNet *********************************************************\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.6477WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 100 batches). You may need to use the repeat() function when building your dataset.\n",
      "5/5 [==============================] - 24s 3s/step - loss: 0.6477 - val_loss: 0.6735\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 3s 570ms/step - loss: 0.5825\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 3s 507ms/step - loss: 0.6961\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 3s 496ms/step - loss: 0.5436\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 3s 519ms/step - loss: 0.4809\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 3s 525ms/step - loss: 0.5051\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 3s 536ms/step - loss: 0.4403\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 3s 554ms/step - loss: 0.4035\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 3s 540ms/step - loss: 0.3950\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 3s 489ms/step - loss: 0.3669\n"
     ]
    }
   ],
   "source": [
    "spe = 5\n",
    "epc = 10\n",
    "vls = 100\n",
    "print(\"Shallow Net ***************************************************\")\n",
    "h1 = shlwClf.fit(x=conjTreinamento, steps_per_epoch=spe, epochs=epc, validation_data=conjTeste, validation_steps=vls, verbose=1).history \n",
    "\n",
    "print(\"LeNet 5 *******************************************************\")\n",
    "h2 = ln5clfM.fit(x=conjTreinamento, steps_per_epoch=spe, epochs=epc, validation_data=conjTeste, validation_steps=vls, verbose=1).history\n",
    "\n",
    "print(\"AlexNet *******************************************************\")\n",
    "h3 = alxClf.fit(x=conjTreinamento, steps_per_epoch=spe, epochs=epc, validation_data=conjTeste, validation_steps=vls, verbose=1).history\n",
    "\n",
    "print(\"Vgg16 *********************************************************\")\n",
    "h4 = vggClf.fit(x=conjTreinamento, steps_per_epoch=spe, epochs=epc, validation_data=conjTeste, validation_steps=vls, verbose=1).history \n",
    "\n",
    "print(\"cxNet *********************************************************\")\n",
    "h5 = cxClf.fit(x=conjTreinamento, steps_per_epoch=spe, epochs=epc, validation_data=conjTeste, validation_steps=vls, verbose=1).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cxNet *********************************************************\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.4170WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 100 batches). You may need to use the repeat() function when building your dataset.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `accuracy` which is not available. Available metrics are: loss,val_loss\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `accuracy` which is not available. Available metrics are: loss,val_loss,lr\n",
      "WARNING:tensorflow:Can save best model only with accuracy available, skipping.\n",
      "5/5 [==============================] - 9s 2s/step - loss: 0.4170 - val_loss: 0.6494 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.3979WARNING:tensorflow:Early stopping conditioned on metric `accuracy` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `accuracy` which is not available. Available metrics are: loss,lr\n",
      "WARNING:tensorflow:Can save best model only with accuracy available, skipping.\n",
      "5/5 [==============================] - 4s 712ms/step - loss: 0.3979 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.4121WARNING:tensorflow:Early stopping conditioned on metric `accuracy` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `accuracy` which is not available. Available metrics are: loss,lr\n",
      "WARNING:tensorflow:Can save best model only with accuracy available, skipping.\n",
      "5/5 [==============================] - 3s 580ms/step - loss: 0.4121 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.4687WARNING:tensorflow:Early stopping conditioned on metric `accuracy` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `accuracy` which is not available. Available metrics are: loss,lr\n",
      "WARNING:tensorflow:Can save best model only with accuracy available, skipping.\n",
      "5/5 [==============================] - 3s 566ms/step - loss: 0.4687 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.3842WARNING:tensorflow:Early stopping conditioned on metric `accuracy` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `accuracy` which is not available. Available metrics are: loss,lr\n",
      "WARNING:tensorflow:Can save best model only with accuracy available, skipping.\n",
      "5/5 [==============================] - 3s 541ms/step - loss: 0.3842 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.4394WARNING:tensorflow:Early stopping conditioned on metric `accuracy` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `accuracy` which is not available. Available metrics are: loss,lr\n",
      "WARNING:tensorflow:Can save best model only with accuracy available, skipping.\n",
      "5/5 [==============================] - 3s 641ms/step - loss: 0.4394 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.4441WARNING:tensorflow:Early stopping conditioned on metric `accuracy` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `accuracy` which is not available. Available metrics are: loss,lr\n",
      "WARNING:tensorflow:Can save best model only with accuracy available, skipping.\n",
      "5/5 [==============================] - 3s 574ms/step - loss: 0.4441 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.4340WARNING:tensorflow:Early stopping conditioned on metric `accuracy` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `accuracy` which is not available. Available metrics are: loss,lr\n",
      "WARNING:tensorflow:Can save best model only with accuracy available, skipping.\n",
      "5/5 [==============================] - 3s 594ms/step - loss: 0.4340 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.3341WARNING:tensorflow:Early stopping conditioned on metric `accuracy` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `accuracy` which is not available. Available metrics are: loss,lr\n",
      "WARNING:tensorflow:Can save best model only with accuracy available, skipping.\n",
      "5/5 [==============================] - 3s 541ms/step - loss: 0.3341 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.3422WARNING:tensorflow:Early stopping conditioned on metric `accuracy` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `accuracy` which is not available. Available metrics are: loss,lr\n",
      "WARNING:tensorflow:Can save best model only with accuracy available, skipping.\n",
      "5/5 [==============================] - 3s 490ms/step - loss: 0.3422 - lr: 0.0010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': [0.4170348048210144,\n",
       "  0.3978901207447052,\n",
       "  0.41207513213157654,\n",
       "  0.46869367361068726,\n",
       "  0.384152352809906,\n",
       "  0.43936339020729065,\n",
       "  0.44405117630958557,\n",
       "  0.43404659628868103,\n",
       "  0.33406496047973633,\n",
       "  0.34217602014541626],\n",
       " 'val_loss': [0.6494277119636536],\n",
       " 'lr': [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001]}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
    "\n",
    "spe = 5\n",
    "epc = 10\n",
    "vls = 100\n",
    "rlr = ReduceLROnPlateau(monitor = 'accuracy', factor = 0.2, patience = 2, verbose = 1, \n",
    "                                min_delta = 1e-4, min_lr = 1e-4, mode = 'max')\n",
    "es = EarlyStopping(monitor = 'accuracy', min_delta = 1e-4, patience = 5, mode = 'max', \n",
    "                    restore_best_weights = True, verbose = 1)\n",
    "\n",
    "ckp = ModelCheckpoint('model.h5',monitor = 'accuracy',\n",
    "                      verbose = 0, save_best_only = True, mode = 'max')\n",
    "\n",
    "#history = model.fit(\n",
    "#      train_generator,\n",
    "#      epochs=20,\n",
    "#      validation_data=valid_generator,\n",
    "#      callbacks=[es,rlr, ckp],\n",
    "#      verbose=1)\n",
    "#Epoch 1/20\n",
    "print(\"cxNet *********************************************************\")\n",
    "h5 = cxClf.fit(x=conjTreinamento, steps_per_epoch=spe, epochs=epc, validation_data=conjTeste, callbacks = [es, rlr, ckp], validation_steps=vls, verbose=1).history\n",
    "h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'accuracy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32md:\\DropB\\Faculeste\\TCC\\codigos\\geraAvaliacao.ipynb Cell 12\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/DropB/Faculeste/TCC/codigos/geraAvaliacao.ipynb#X30sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m plt\u001b[39m.\u001b[39mplot(np\u001b[39m.\u001b[39marange(\u001b[39m0\u001b[39m,\u001b[39m10\u001b[39m), h3[\u001b[39m\"\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m\"\u001b[39m], label\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mAlexNet\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/DropB/Faculeste/TCC/codigos/geraAvaliacao.ipynb#X30sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m plt\u001b[39m.\u001b[39mplot(np\u001b[39m.\u001b[39marange(\u001b[39m0\u001b[39m,\u001b[39m10\u001b[39m), h4[\u001b[39m\"\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m\"\u001b[39m], label\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mVGG 16\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/DropB/Faculeste/TCC/codigos/geraAvaliacao.ipynb#X30sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m plt\u001b[39m.\u001b[39mplot(np\u001b[39m.\u001b[39marange(\u001b[39m0\u001b[39m,\u001b[39m10\u001b[39m), h5[\u001b[39m\"\u001b[39;49m\u001b[39maccuracy\u001b[39;49m\u001b[39m\"\u001b[39;49m], label\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCheXNet\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/DropB/Faculeste/TCC/codigos/geraAvaliacao.ipynb#X30sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m plt\u001b[39m.\u001b[39mtitle(\u001b[39m\"\u001b[39m\u001b[39mAcurcia no Treinamento - Covid-19\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/DropB/Faculeste/TCC/codigos/geraAvaliacao.ipynb#X30sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m plt\u001b[39m.\u001b[39mxlabel(\u001b[39m\"\u001b[39m\u001b[39mpocas\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'accuracy'"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0,10), h1[\"accuracy\"], label=\"Shallow Net\")\n",
    "plt.plot(np.arange(0,10), h2[\"accuracy\"], label=\"LeNet 5\")\n",
    "plt.plot(np.arange(0,10), h3[\"accuracy\"], label=\"AlexNet\")\n",
    "plt.plot(np.arange(0,10), h4[\"accuracy\"], label=\"VGG 16\")\n",
    "plt.plot(np.arange(0,10), h5[\"accuracy\"], label=\"CheXNet\")\n",
    "plt.title(\"Acurcia no Treinamento - Covid-19\")\n",
    "plt.xlabel(\"pocas\")\n",
    "plt.ylabel(\"Acurcia\")\n",
    "plt.legend()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
